{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a594a79f-4113-4365-bb7e-77bd6d7ef617",
   "metadata": {},
   "source": [
    "## MIMIC_III QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f25b5a-abab-4ac8-9544-616f421ad63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "with open('test_final.json', 'r') as f:\n",
    "    data = json.load(f)  # Could be a list or dictionary\n",
    "\n",
    "# Check structure\n",
    "print(f\"Data type: {type(data)}\")\n",
    "if isinstance(data, list):\n",
    "    print(f\"Number of QA pairs: {len(data)}\")\n",
    "    print(\"First item:\", data[0])  # Inspect first entry\n",
    "elif isinstance(data, dict):\n",
    "    print(f\"Keys: {data.keys()}\")\n",
    "    print(\"Sample item:\", next(iter(data.items())))  # Inspect first key-value pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ecbf7b-aa5e-4c1a-bc2a-11a3233b1e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('test_final.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract all QA pairs\n",
    "qa_pairs = []\n",
    "for item in data['data']:\n",
    "    for paragraph in item['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            qa_pairs.append({\n",
    "                'id': qa['id'],\n",
    "                'question': qa['question'],\n",
    "                'answer': qa['answers'][0]['text'],  # Take the first answer\n",
    "                'context': context\n",
    "            })\n",
    "\n",
    "# Print a sample\n",
    "print(f\"Total QA pairs: {len(qa_pairs)}\")\n",
    "print(\"\\nSample QA pair:\")\n",
    "print(f\"Question: {qa_pairs[0]['question']}\")\n",
    "print(f\"Answer: {qa_pairs[0]['answer']}\")\n",
    "print(f\"Context snippet: {qa_pairs[0]['context'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e20ba-f886-42a0-bf1b-acabaeb00e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the JSON file\n",
    "with open('test_final.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract all QA pairs into a list of dictionaries\n",
    "qa_records = []\n",
    "for item in data['data']:\n",
    "    for paragraph in item['paragraphs']:\n",
    "        context = paragraph['context']\n",
    "        for qa in paragraph['qas']:\n",
    "            qa_records.append({\n",
    "                'id': qa['id'],\n",
    "                'question': qa['question'],\n",
    "                'answer': qa['answers'][0]['text'],  # Take the first answer\n",
    "                'answer_start': qa['answers'][0]['answer_start'],  # Start position in context\n",
    "                'context': context\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(qa_records)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b544ca-f923-4e75-ab5a-161be5f92963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV (without index)\n",
    "df.to_csv('mimic_qa_dataset.csv', index=False)\n",
    "\n",
    "print(\"CSV file saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad4785-ebba-4cdc-bab1-5c0fa626d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(f\"CSV saved at: {os.path.abspath('mimic_qa_dataset.csv')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4017ac9c-a18d-4265-94bc-0239ad2f9c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"mimic_qa_dataset.csv\")  # Replace with the actual path\n",
    "\n",
    "# Function to clean and extract structured clinical input\n",
    "def refine_clinical_summary_v2(context):\n",
    "    if pd.isnull(context): return \"\"\n",
    "    \n",
    "    # Remove [** ... **] tokens and normalize whitespace\n",
    "    context = re.sub(r\"\\[\\*\\*.*?\\*\\*\\]\", \"\", context)\n",
    "    context = re.sub(r\"\\s+\", \" \", context).strip()\n",
    "\n",
    "    parts = []\n",
    "\n",
    "    # Chief Complaint\n",
    "    cc = re.search(r'chief complaint:\\s*(.*?)(?=major surgical|history of present illness|review of systems|past medical history|social history|physical exam|$)', context, re.IGNORECASE | re.DOTALL)\n",
    "    if cc:\n",
    "        parts.append(\"Chief Complaint: \" + cc.group(1).strip())\n",
    "\n",
    "    # History of Present Illness\n",
    "    hpi = re.search(r'history of present illness:\\s*(.*?)(?=review of systems|past medical history|social history|physical exam|brief hospital course|$)', context, re.IGNORECASE | re.DOTALL)\n",
    "    if hpi:\n",
    "        parts.append(\"HPI: \" + hpi.group(1).strip())\n",
    "\n",
    "    # Emergency Notes\n",
    "    ed_lines = [line.strip() for line in context.split(\".\") if any(k in line.lower() for k in [\"ems\", \"er\", \"ed\", \"emergency\"])]\n",
    "    if ed_lines:\n",
    "        parts.append(\"ED Notes: \" + \" \".join(ed_lines))\n",
    "\n",
    "    # Lab Findings\n",
    "    lab_lines = []\n",
    "    for line in context.split(\".\"):\n",
    "        if any(k in line.lower() for k in [\"wbc\", \"lactate\", \"leukocytosis\", \"labs\"]):\n",
    "            cleaned = line.strip().replace(\"if\", \"of\").replace(\"wbc-\", \"WBC: \").replace(\"lactate\", \"Lactate\")\n",
    "            lab_lines.append(cleaned)\n",
    "    if lab_lines:\n",
    "        parts.append(\"Lab Findings: \" + \" \".join(lab_lines))\n",
    "\n",
    "    # Treatment\n",
    "    meds = [\"solumedrol\", \"nebulizer\", \"levofloxacin\", \"azithromycin\", \"aspirin\", \"magnesium\", \"ceftriaxone\", \"combivent\"]\n",
    "    tx_lines = [line.strip() for line in context.split(\".\") if any(m in line.lower() for m in meds)]\n",
    "    if tx_lines:\n",
    "        parts.append(\"Treatment Given: \" + \" \".join(tx_lines))\n",
    "\n",
    "    return \"\\n\".join(parts)[:1200]\n",
    "\n",
    "# Apply function to context column\n",
    "df[\"input\"] = df[\"context\"].apply(refine_clinical_summary_v2)\n",
    "\n",
    "# Create instruction/output columns\n",
    "df[\"instruction\"] = df[\"question\"]\n",
    "df[\"output\"] = df[\"answer\"]\n",
    "\n",
    "# Select final columns\n",
    "final_df = df[[\"instruction\", \"input\", \"output\"]]\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = \"MIMIC_III_QA_Refined_Final.csv\"\n",
    "final_df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Save to JSONL\n",
    "jsonl_path = \"MIMIC_III_QA_Refined_Final.jsonl\"\n",
    "with open(jsonl_path, \"w\") as f:\n",
    "    for _, row in final_df.iterrows():\n",
    "        json.dump({\n",
    "            \"instruction\": row[\"instruction\"],\n",
    "            \"input\": row[\"input\"],\n",
    "            \"output\": row[\"output\"]\n",
    "        }, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"âœ… Saved:\")\n",
    "print(f\"- {csv_path}\")\n",
    "print(f\"- {jsonl_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065a441d-441e-4a79-8c70-aa82ecbcf251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae8c3af-af3f-4189-9284-f0bc4be1b5ae",
   "metadata": {},
   "source": [
    "## MIMIC_IV QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe7a593-8f99-4f8b-9465-4b095291a775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# === FILE PATHS ===\n",
    "QA_FILE = \"MIMIC_IV_FINAL_QA.csv\"          # Replace with actual path\n",
    "MERGED_FILE = \"merged_mimic_IV.csv\"        # Your merged file with vitals, meds, diagnoses\n",
    "\n",
    "# === LOAD DATA ===\n",
    "qa_df = pd.read_csv(QA_FILE)\n",
    "merged_df = pd.read_csv(MERGED_FILE)\n",
    "\n",
    "# === GROUP MERGED DATA BY PATIENT ===\n",
    "def build_patient_context(group):\n",
    "    parts = []\n",
    "\n",
    "    # Demographics\n",
    "    gender = group[\"gender\"].dropna().unique()\n",
    "    if gender.size > 0:\n",
    "        parts.append(f\"Gender: {gender[0]}\")\n",
    "\n",
    "    # Chief complaint\n",
    "    cc = group[\"chiefcomplaint\"].dropna().unique()\n",
    "    if cc.size > 0:\n",
    "        parts.append(f\"Chief Complaint: {cc[0]}\")\n",
    "\n",
    "    # Diagnoses\n",
    "    diagnoses = group[\"icd_title\"].dropna().unique()\n",
    "    if diagnoses.size > 0:\n",
    "        parts.append(\"Diagnoses: \" + \", \".join(diagnoses[:5]))  # limit to top 5\n",
    "\n",
    "    # Vitals (mean values)\n",
    "    vitals = {\n",
    "        \"Temp\": group[\"temperature\"].mean(),\n",
    "        \"HR\": group[\"heartrate\"].mean(),\n",
    "        \"RR\": group[\"resprate\"].mean(),\n",
    "        \"O2Sat\": group[\"o2sat\"].mean(),\n",
    "        \"SBP\": group[\"sbp\"].mean(),\n",
    "        \"DBP\": group[\"dbp\"].mean()\n",
    "    }\n",
    "    vitals_str = \", \".join([f\"{k} {round(v, 1)}\" for k, v in vitals.items() if pd.notna(v)])\n",
    "    if vitals_str:\n",
    "        parts.append(\"Vitals: \" + vitals_str)\n",
    "\n",
    "    # Medications\n",
    "    meds = group[\"name\"].dropna().unique()\n",
    "    if len(meds) > 0:\n",
    "        parts.append(\"Medications Given: \" + \", \".join(meds[:5]))  # limit to top 5\n",
    "\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# Create structured input per patient\n",
    "patient_inputs = merged_df.groupby(\"subject_id\").apply(build_patient_context).reset_index()\n",
    "patient_inputs.columns = [\"patient_id\", \"input\"]\n",
    "\n",
    "# === MERGE WITH QA ===\n",
    "qa_merged = qa_df.merge(patient_inputs, on=\"patient_id\", how=\"left\")\n",
    "qa_merged[\"instruction\"] = qa_merged[\"question\"]\n",
    "qa_merged[\"output\"] = qa_merged[\"correct_answer\"]\n",
    "\n",
    "# Keep final columns\n",
    "final_df = qa_merged[[\"instruction\", \"input\", \"output\"]]\n",
    "\n",
    "# === SAVE OUTPUT ===\n",
    "final_df.to_csv(\"MIMIC_IV_QA_Structured.csv\", index=False)\n",
    "\n",
    "with open(\"MIMIC_IV_QA_Structured.jsonl\", \"w\") as f:\n",
    "    for _, row in final_df.iterrows():\n",
    "        json.dump({\n",
    "            \"instruction\": row[\"instruction\"],\n",
    "            \"input\": row[\"input\"],\n",
    "            \"output\": row[\"output\"]\n",
    "        }, f)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"âœ… Saved:\")\n",
    "print(\"- MIMIC_IV_QA_Structured.csv\")\n",
    "print(\"- MIMIC_IV_QA_Structured.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0b946-df26-4672-b26f-22e7b419ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load QA File ===\n",
    "qa_df = pd.read_csv(\"MIMIC_IV_FINAL_QA.csv\")\n",
    "\n",
    "# === Load Clinical CSVs ===\n",
    "diagnosis = pd.read_csv(\"diagnosis.csv\")\n",
    "edstays = pd.read_csv(\"edstays.csv\")\n",
    "medrecon = pd.read_csv(\"medrecon.csv\")\n",
    "pyxis = pd.read_csv(\"pyxis.csv\")\n",
    "triage = pd.read_csv(\"triage.csv\")\n",
    "vitals = pd.read_csv(\"vitalsign.csv\")\n",
    "\n",
    "# === Filter All Clinical Data to QA Patient IDs ===\n",
    "qa_patients = qa_df[\"patient_id\"].unique()\n",
    "\n",
    "diagnosis = diagnosis[diagnosis[\"subject_id\"].isin(qa_patients)]\n",
    "edstays = edstays[edstays[\"subject_id\"].isin(qa_patients)]\n",
    "medrecon = medrecon[medrecon[\"subject_id\"].isin(qa_patients)]\n",
    "pyxis = pyxis[pyxis[\"subject_id\"].isin(qa_patients)]\n",
    "triage = triage[triage[\"subject_id\"].isin(qa_patients)]\n",
    "vitals = vitals[vitals[\"subject_id\"].isin(qa_patients)]\n",
    "\n",
    "# === Function to Build Input Summary ===\n",
    "def build_input(subject_id):\n",
    "    parts = []\n",
    "\n",
    "    # Chief Complaint\n",
    "    cc = triage[triage[\"subject_id\"] == subject_id][\"chiefcomplaint\"].dropna().unique()\n",
    "    if cc.size > 0:\n",
    "        parts.append(f\"Chief Complaint: {cc[0]}\")\n",
    "\n",
    "    # Gender\n",
    "    gender = edstays[edstays[\"subject_id\"] == subject_id][\"gender\"].dropna().unique()\n",
    "    if gender.size > 0:\n",
    "        parts.append(f\"Gender: {gender[0]}\")\n",
    "\n",
    "    # Diagnoses\n",
    "    dx = diagnosis[diagnosis[\"subject_id\"] == subject_id][\"icd_title\"].dropna().unique()\n",
    "    if dx.size > 0:\n",
    "        parts.append(\"Diagnoses: \" + \", \".join(dx[:5]))\n",
    "\n",
    "    # Vitals\n",
    "    vdf = vitals[vitals[\"subject_id\"] == subject_id]\n",
    "    vitals_vals = {\n",
    "        \"Temp\": vdf[\"temperature\"].mean(),\n",
    "        \"HR\": vdf[\"heartrate\"].mean(),\n",
    "        \"RR\": vdf[\"resprate\"].mean(),\n",
    "        \"O2Sat\": vdf[\"o2sat\"].mean(),\n",
    "        \"SBP\": vdf[\"sbp\"].mean(),\n",
    "        \"DBP\": vdf[\"dbp\"].mean(),\n",
    "    }\n",
    "    vitals_text = \", \".join([f\"{k} {round(v,1)}\" for k, v in vitals_vals.items() if pd.notna(v)])\n",
    "    if vitals_text:\n",
    "        parts.append(\"Vitals: \" + vitals_text)\n",
    "\n",
    "    # Medications\n",
    "    meds1 = medrecon[medrecon[\"subject_id\"] == subject_id][\"name\"].dropna().unique()\n",
    "    meds2 = pyxis[pyxis[\"subject_id\"] == subject_id][\"name\"].dropna().unique()\n",
    "    meds = pd.Series(list(meds1) + list(meds2)).dropna().unique()\n",
    "    if meds.size > 0:\n",
    "        parts.append(\"Medications Given: \" + \", \".join(meds[:5]))\n",
    "\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# === Build Input Context per Patient ===\n",
    "input_rows = [{\"patient_id\": sid, \"input\": build_input(sid)} for sid in qa_patients]\n",
    "input_df = pd.DataFrame(input_rows)\n",
    "\n",
    "# === Merge With QA ===\n",
    "qa_final = qa_df.merge(input_df, on=\"patient_id\", how=\"left\")\n",
    "qa_final[\"instruction\"] = qa_final[\"question\"]\n",
    "qa_final[\"output\"] = qa_final[\"correct_answer\"]\n",
    "\n",
    "final_df = qa_final[[\"instruction\", \"input\", \"output\"]]\n",
    "final_df.to_csv(\"MIMIC_IV_QA_Completed.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved: MIMIC_IV_QA_Completed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec2808-6194-42b5-ab8f-00faf4e4f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(\"MIMIC_IV_QA_Completed.csv\")\n",
    "\n",
    "# Fill missing inputs with a generic placeholder\n",
    "df[\"input\"] = df[\"input\"].fillna(\"No structured clinical data available.\")\n",
    "\n",
    "# Save the new file\n",
    "df.to_csv(\"MIMIC_IV_QA_Final_Placeholder.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved: MIMIC_IV_QA_Final_Placeholder.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a1f63-8e93-4ed3-91c6-c0450b96a16e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc735d7-4900-47ab-b75c-5ca55a218ba4",
   "metadata": {},
   "source": [
    "## MIMIC_QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b6b0a-32c0-4df7-b727-c9815964b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the mimic_iv_note_qa.csv file\n",
    "qa_df = pd.read_csv(\"mimic_iv_note_qa.csv\")\n",
    "\n",
    "# Expand qa_pairs into multiple rows\n",
    "expanded_rows = []\n",
    "\n",
    "for _, row in qa_df.iterrows():\n",
    "    subject_id = row.get(\"subject_id\")\n",
    "    note_id = row.get(\"note_id\")\n",
    "    hadm_id = row.get(\"hadm_id\")\n",
    "    \n",
    "    try:\n",
    "        qa_list = json.loads(row[\"qa_pairs\"])\n",
    "        for qa in qa_list:\n",
    "            question = qa.get(\"question\", \"\").strip()\n",
    "            answer = qa.get(\"answer\", \"\").strip()\n",
    "            if question and answer:\n",
    "                expanded_rows.append({\n",
    "                    \"subject_id\": subject_id,\n",
    "                    \"note_id\": note_id,\n",
    "                    \"hadm_id\": hadm_id,\n",
    "                    \"instruction\": question,\n",
    "                    \"output\": answer\n",
    "                })\n",
    "    except json.JSONDecodeError:\n",
    "        continue\n",
    "\n",
    "# Convert to DataFrame\n",
    "qa_expanded = pd.DataFrame(expanded_rows)\n",
    "qa_expanded.to_csv(\"mimic_iv_note_qa_expanded.csv\", index=False)\n",
    "print(\"âœ… Saved: mimic_iv_note_qa_expanded.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06aa1b4-be69-4e42-af98-2fe039e5561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Diagnosis columns:\", diagnosis.columns)\n",
    "print(\"Medrecon columns:\", medrecon.columns)\n",
    "print(\"Pyxis columns:\", pyxis.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6878d57-b08d-449c-b7e9-635099bda128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load Files ===\n",
    "qa_df = pd.read_csv(\"mimic_iv_note_qa_expanded.csv\")\n",
    "edstays = pd.read_csv(\"edstays.csv\")\n",
    "diagnosis = pd.read_csv(\"diagnosis.csv\")\n",
    "medrecon = pd.read_csv(\"medrecon.csv\")\n",
    "pyxis = pd.read_csv(\"pyxis.csv\")\n",
    "triage = pd.read_csv(\"triage.csv\")\n",
    "vitals = pd.read_csv(\"vitalsign.csv\")\n",
    "\n",
    "# === Step 1: Merge edstays to bring in stay_id and gender ===\n",
    "qa_df = qa_df.merge(edstays[[\"subject_id\", \"hadm_id\", \"stay_id\", \"gender\"]], on=[\"subject_id\", \"hadm_id\"], how=\"left\")\n",
    "\n",
    "# === Step 2: Drop rows without stay_id ===\n",
    "qa_df = qa_df.dropna(subset=[\"stay_id\"])\n",
    "qa_df[\"stay_id\"] = qa_df[\"stay_id\"].astype(int)\n",
    "qa_df[\"subject_id\"] = qa_df[\"subject_id\"].astype(int)\n",
    "\n",
    "# === Step 3: Filter structured data to only needed patients ===\n",
    "patient_keys = qa_df[[\"subject_id\", \"stay_id\"]].drop_duplicates()\n",
    "\n",
    "def filter_by_keys(df, keys):\n",
    "    return df.merge(keys, on=[\"subject_id\", \"stay_id\"], how=\"inner\")\n",
    "\n",
    "diagnosis = filter_by_keys(diagnosis, patient_keys)\n",
    "medrecon = filter_by_keys(medrecon, patient_keys)\n",
    "pyxis = filter_by_keys(pyxis, patient_keys)\n",
    "triage = filter_by_keys(triage, patient_keys)\n",
    "vitals = filter_by_keys(vitals, patient_keys)\n",
    "\n",
    "# === Step 4: Build structured input per patient admission ===\n",
    "def build_input(sid, stay_id, gender=None):\n",
    "    parts = []\n",
    "\n",
    "    if pd.notna(gender):\n",
    "        parts.append(f\"Gender: {gender}\")\n",
    "\n",
    "    # Chief Complaint\n",
    "    cc = triage[(triage[\"subject_id\"] == sid) & (triage[\"stay_id\"] == stay_id)][\"chiefcomplaint\"].dropna().unique()\n",
    "    if cc.size > 0:\n",
    "        parts.append(f\"Chief Complaint: {cc[0]}\")\n",
    "\n",
    "    # Diagnoses\n",
    "    dx = diagnosis[(diagnosis[\"subject_id\"] == sid) & (diagnosis[\"stay_id\"] == stay_id)][\"icd_title\"].dropna().unique()\n",
    "    if dx.size > 0:\n",
    "        parts.append(\"Diagnoses: \" + \", \".join(dx[:5]))\n",
    "\n",
    "    # Vitals\n",
    "    vdf = vitals[(vitals[\"subject_id\"] == sid) & (vitals[\"stay_id\"] == stay_id)]\n",
    "    vitals_avg = {\n",
    "        \"Temp\": vdf[\"temperature\"].mean(),\n",
    "        \"HR\": vdf[\"heartrate\"].mean(),\n",
    "        \"RR\": vdf[\"resprate\"].mean(),\n",
    "        \"O2Sat\": vdf[\"o2sat\"].mean(),\n",
    "        \"SBP\": vdf[\"sbp\"].mean(),\n",
    "        \"DBP\": vdf[\"dbp\"].mean()\n",
    "    }\n",
    "    vitals_str = \", \".join([f\"{k} {round(v,1)}\" for k, v in vitals_avg.items() if pd.notna(v)])\n",
    "    if vitals_str:\n",
    "        parts.append(\"Vitals: \" + vitals_str)\n",
    "\n",
    "    # Medications\n",
    "    meds1 = medrecon[(medrecon[\"subject_id\"] == sid) & (medrecon[\"stay_id\"] == stay_id)][\"name\"].dropna().unique()\n",
    "    meds2 = pyxis[(pyxis[\"subject_id\"] == sid) & (pyxis[\"stay_id\"] == stay_id)][\"name\"].dropna().unique()\n",
    "    meds = pd.Series(list(meds1) + list(meds2)).dropna().unique()\n",
    "    if meds.size > 0:\n",
    "        parts.append(\"Medications Given: \" + \", \".join(meds[:5]))\n",
    "\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "# === Step 5: Apply input generation ===\n",
    "qa_df[\"input\"] = qa_df.apply(lambda row: build_input(row[\"subject_id\"], row[\"stay_id\"], row.get(\"gender\")), axis=1)\n",
    "\n",
    "# === Step 6: Save final dataset ===\n",
    "qa_final = qa_df[[\"instruction\", \"input\", \"output\"]]\n",
    "qa_final.to_csv(\"mimic_iv_final_structured_qa_stay.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved: mimic_iv_final_structured_qa_stay.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3440b7-32fb-4f41-a846-3babf9fd8a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15da2b-0dc4-4b82-a80e-f415a2e8929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591424e8-0fc7-431f-8e14-7f5602815e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"mimic_iv_final_structured_qa_stay.csv\")\n",
    "\n",
    "# For diagnosis-related answers, extract labels (adjust based on your task)\n",
    "diagnosis_counts = df[\"output\"].str.extract(r\"(COPD|HIV|Hypertension|Pneumonia|Fracture)\")[0].value_counts()\n",
    "\n",
    "print(diagnosis_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec31ec-ec96-41e4-82af-b8e2a1d81b81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4703a7f-50be-4e78-86a9-6c57ec712587",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "145055bc-1489-4fdb-a908-b8d16c0d88da",
   "metadata": {},
   "source": [
    "## combined csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b853b-de6d-4251-8edc-5b5456eec676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === Load the files ===\n",
    "mimic_iv_stay = pd.read_csv(\"mimic_iv_final_structured_qa_stay.csv\")\n",
    "mimic_iv_placeholder = pd.read_csv(\"MIMIC_IV_QA_Final_Placeholder.csv\")\n",
    "mimic_iii = pd.read_csv(\"MIMIC_III_QA_Refined_Final.csv\")\n",
    "\n",
    "# === Standardize column names (lowercase) ===\n",
    "for df in [mimic_iv_stay, mimic_iv_placeholder, mimic_iii]:\n",
    "    df.rename(columns=lambda x: x.strip().lower(), inplace=True)\n",
    "\n",
    "# === Keep only the necessary columns ===\n",
    "columns_needed = [\"instruction\", \"input\", \"output\"]\n",
    "for df in [mimic_iv_stay, mimic_iv_placeholder, mimic_iii]:\n",
    "    if not all(col in df.columns for col in columns_needed):\n",
    "        raise ValueError(\"One or more required columns are missing in a file\")\n",
    "\n",
    "# === Merge all three ===\n",
    "combined_df = pd.concat([\n",
    "    mimic_iv_stay[columns_needed],\n",
    "    mimic_iv_placeholder[columns_needed],\n",
    "    mimic_iii[columns_needed]\n",
    "], ignore_index=True)\n",
    "\n",
    "# === Save the final merged file ===\n",
    "combined_df.to_csv(\"mimic_qa_combined.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… Saved: mimic_qa_combined.csv with {len(combined_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4787f44-433d-471f-b82e-c039611c9758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb969e-bae1-4468-8dde-96c2e0d87359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec8a9f33-c77c-4f2f-918e-7eecbf61ec39",
   "metadata": {},
   "source": [
    "## preprocessing medquad and icliniq QA datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3f799-484c-468c-a6fb-afdaa571b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load MedQuAD\n",
    "df = pd.read_csv(\"medquad.csv\")\n",
    "\n",
    "# Clean whitespace and drop NaNs\n",
    "df = df.dropna(subset=[\"question\", \"focus_area\", \"answer\"])\n",
    "df[\"question\"] = df[\"question\"].str.strip()\n",
    "df[\"focus_area\"] = df[\"focus_area\"].str.strip()\n",
    "df[\"answer\"] = df[\"answer\"].str.strip()\n",
    "\n",
    "# Remove very short or empty responses\n",
    "df = df[df[\"answer\"].str.len() > 20]\n",
    "\n",
    "# Remove duplicate Q-A pairs\n",
    "df = df.drop_duplicates(subset=[\"question\", \"answer\"])\n",
    "\n",
    "# Rename to match BioMistral format\n",
    "df = df.rename(columns={\n",
    "    \"question\": \"instruction\",\n",
    "    \"focus_area\": \"input\",\n",
    "    \"answer\": \"output\"\n",
    "})\n",
    "\n",
    "# Optional: Normalize line breaks and spacing\n",
    "for col in [\"instruction\", \"input\", \"output\"]:\n",
    "    df[col] = df[col].str.replace(r\"\\s+\", \" \", regex=True)\n",
    "\n",
    "# Save preprocessed version\n",
    "df.to_csv(\"medquad_preprocessed.csv\", index=False)\n",
    "print(\"âœ… Saved: medquad_preprocessed.csv with\", len(df), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a5e32-9b31-4377-813a-c1fb8f621342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"icliniq_medical_qa_cleaned.csv\")\n",
    "\n",
    "# Drop rows with missing fields\n",
    "df = df.dropna(subset=[\"Title\", \"Question\", \"Answer\"])\n",
    "\n",
    "# Rename to standard format\n",
    "df = df.rename(columns={\n",
    "    \"Question\": \"instruction\",\n",
    "    \"Title\": \"input\",\n",
    "    \"Answer\": \"output\"\n",
    "})\n",
    "\n",
    "# Clean whitespace\n",
    "for col in [\"instruction\", \"input\", \"output\"]:\n",
    "    df[col] = df[col].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Filter: remove very short answers (<20 characters)\n",
    "df = df[df[\"output\"].str.len() > 20]\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=[\"instruction\", \"output\"])\n",
    "\n",
    "# Save final processed version\n",
    "df.to_csv(\"icliniq_preprocessed.csv\", index=False)\n",
    "print(f\"âœ… Saved: icliniq_preprocessed.csv with {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6507800-c05e-45db-b638-f821db0821ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c83fd71-71b7-4b75-a7cc-543d3dfee9f7",
   "metadata": {},
   "source": [
    "## merge csv file with processed medquad and icliniq datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d7a83-84bd-4763-ab6c-b232381652b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load preprocessed files\n",
    "mimic = pd.read_csv(\"mimic_qa_combined.csv\")\n",
    "medquad = pd.read_csv(\"medquad_preprocessed.csv\")\n",
    "icliniq = pd.read_csv(\"icliniq_preprocessed.csv\")\n",
    "\n",
    "# Ensure column names are standardized\n",
    "for df in [mimic, medquad, icliniq]:\n",
    "    df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Ensure all required columns are present\n",
    "columns = [\"instruction\", \"input\", \"output\"]\n",
    "for df in [mimic, medquad, icliniq]:\n",
    "    if not all(col in df.columns for col in columns):\n",
    "        raise ValueError(\"Missing one of 'instruction', 'input', or 'output' in a dataset.\")\n",
    "\n",
    "# Combine\n",
    "final_df = pd.concat(\n",
    "    [mimic[columns], medquad[columns], icliniq[columns]],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Optional: deduplicate\n",
    "final_df.drop_duplicates(subset=[\"instruction\", \"input\", \"output\"], inplace=True)\n",
    "\n",
    "# Save merged dataset\n",
    "final_df.to_csv(\"bio_mistral_qa_combined.csv\", index=False)\n",
    "print(f\"âœ… Saved: bio_mistral_qa_combined.csv with {len(final_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dfa746-3bfd-45a7-9ba8-fcb648c2e34b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
